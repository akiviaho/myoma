{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from logzero import logger\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution() # To enable Tensor.numpy() member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPLEMENTED ##\n",
    "# 1. Modify tile names to get rid of wild/tumor label\n",
    "# 2. Create csv of tile names to connect to samples \n",
    "# Load tiles and create appropriate number of TFRecords\n",
    "# Script for reading 8 samples at a time into the model (see below)\n",
    "# Save tfrecords of 800 jpgs each\n",
    "    # train_set and test_set separately.\n",
    "# Create tsv-files to read into tf.data.tfrecorddataset.\n",
    "\n",
    "## TODOS ####\n",
    "# Move the files into /lustre/nvme/ and use modify inception driver script to read these files \n",
    "\n",
    "\n",
    "## ON HOLD ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle samples for division into train and test sets\n",
    "sample_sheet = pd.read_csv('/lustre/scratch/kiviaho/myoma/myoma-new/sample_sheet_with_mutation_type_tile_path.tsv',sep=\"\\t\")\n",
    "df = pd.DataFrame(list(dict.fromkeys(sample_sheet['Sample']))) # This preserves the order, unlike set !!\n",
    "df = df.sample(frac=1,random_state=11).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splits for sample\n",
    "train_n = round(0.8*len(df))\n",
    "test_n = len(df)-train_n\n",
    "train_samples = df.head(train_n)\n",
    "test_samples = df.tail(test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide samples and shuffle\n",
    "train_set = sample_sheet.loc[sample_sheet['Sample'].isin(train_samples[0])]\n",
    "train_set = train_set.sample(frac=1,random_state=11).reset_index(drop=True)\n",
    "\n",
    "test_set = sample_sheet.loc[sample_sheet['Sample'].isin(test_samples[0])]\n",
    "test_set = test_set.sample(frac=1,random_state=11).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datatypes with tf.train.feature\n",
    "def _array_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a array.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.numpy()]))\n",
    "    \n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one serialization of a datapoint.\n",
    "# Takes img array, encoded label and img shape as input\n",
    "def serialize_example(img, label):\n",
    "    \"\"\"\n",
    "    Creates a tf.train.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
    "    # data type.\n",
    "    feature = {\n",
    "      'img': _array_feature(img),\n",
    "      'label':  _bytes_feature(label),\n",
    "    }\n",
    "    # Create a Features message using tf.train.Example.\n",
    "    \n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "def np_to_serialized_tensor(arr):\n",
    "    arr = tf.constant(arr,dtype=tf.int16)\n",
    "    arr = tf.io.serialize_tensor(arr)\n",
    "    return arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecords_from_csv(sample_set, batch_size, write_path):\n",
    "    ''' \n",
    "    Writes jpgs into a set of tfrecord-files defined by the first argument. \n",
    "    Number of jpg's written into a single TFRecord is defined by batch_size.\n",
    "    \n",
    "    params:\n",
    "        sample_set: A data-frame of shape nx3, with columns 'Sample', 'Type' and 'Tile'.\n",
    "        batch_size: The number of jpg-files to be written into a single TFRecord\n",
    "        write_path: Write path, relative or absolute\n",
    "        \n",
    "    returns:\n",
    "        sample_set: A dataframe of shape nx4, with column 'TFRecords' specifying the file\n",
    "        into which the particular tile has been written into.\n",
    "    '''\n",
    "    # Define the number of TFRecord-files to be written\n",
    "    n_batches = np.floor(len(sample_set)/batch_size).astype(int)\n",
    "    batch_res = len(sample_set)-batch_size*n_batches\n",
    "    tfrecords = []\n",
    "    \n",
    "    # Write the full-batch TFRecords\n",
    "    for it in range(n_batches):\n",
    "        if it%10 == 0:\n",
    "            logger.info(\"Writing TFRecord \"+ str(it) +\" of \"+ str(n_batches+1))\n",
    "        start = time.time()\n",
    "        subset = sample_set[int(batch_size*it):int(batch_size*(it+1))]\n",
    "        subset = subset.reset_index(drop=True)\n",
    "        filename = write_path + str(it) + '.tfrecord'\n",
    "        tfrecords = np.hstack((tfrecords,np.repeat(filename,batch_size)))\n",
    "\n",
    "        labels = subset['Type']\n",
    "        img_paths = subset['Tile']\n",
    "        with tf.io.TFRecordWriter(filename) as writer:\n",
    "            for i in range(batch_size):\n",
    "                img_bytes = open(img_paths[i],'rb').read()\n",
    "                img_bytes = tf.io.serialize_tensor(img_bytes)\n",
    "                example = serialize_example(img_bytes,labels[i].encode())\n",
    "                writer.write(example)\n",
    "    \n",
    "    # Write the last \"partial\" batch\n",
    "    subset = sample_set[int(batch_size*n_batches):int(batch_size*n_batches+batch_res)]\n",
    "    subset = subset.reset_index(drop=True)\n",
    "    filename = write_path + str(n_batches+1) + '.tfrecord'\n",
    "    tfrecords = np.hstack((tfrecords,np.repeat(filename,batch_res)))\n",
    "\n",
    "    labels = subset['Type']\n",
    "    img_paths = subset['Tile']\n",
    "    with tf.io.TFRecordWriter(filename) as writer:\n",
    "        for i in range(batch_res):\n",
    "            img_bytes = open(img_paths[i],'rb').read()\n",
    "            img_bytes = tf.io.serialize_tensor(img_bytes)\n",
    "            example = serialize_example(img_bytes,labels[i].encode())\n",
    "            writer.write(example)\n",
    "    \n",
    "    sample_set['TFRecords'] = tfrecords.tolist()\n",
    "    return sample_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function pipeline\n",
    "Path('tmp/').mkdir(parents=True,exist_ok=True)\n",
    "sample = train_set\n",
    "sample = write_tfrecords_from_csv(sample, 800, 'tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
